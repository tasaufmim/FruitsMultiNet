
Introduction
The breakthrough of smart supply chain systems and the rapid adoption of automation in the fruit growing and manufacturing sectors are driving the increasing demand for an automatic fruit classification approach. The proposed research suggests a groundbreaking autonomous fruit classification method based on convolutional neural networks (CNNs). The classification of fruits is often challenging due to variations that occur in the same fruit throughout its life cycle. Additionally, the diverse compositions of sizes, shapes, and colors further complicate the process and impact accuracy. This research worked with a unique dataset of 3,240 images of Bangladeshi fruits, publicly available on Kaggle. The data were preprocessed before the feature extraction phase to achieve more accurate outcomes. MobileNet, VGG16, NasNetMobile, DenseNet201, InceptionV3, and Xception were experimented with in the feature extraction and performance evaluation process. The proposed research combined MobileNet and VGG16 to build a transfer learning principles-based framework named ‘FruitsMultiNet’. The data were divided into training, testing, and validation sets for eight different fruits. The proposed ‘FruitsMultiNet’ achieved a 99.84% accuracy rate, which is higher than the accuracy rates of individual deep learning models. The integration of ‘FruitsMultiNet’ into a mobile application makes it easily accessible for individuals, adding consistency and providing consumers with a more accessible system to classify fruits automatically, while also showing the benefits for human health. 

Dataset URL: https://www.kaggle.com/datasets/shimulmbstu/fruitsdataset

Mobile App Lin: 
